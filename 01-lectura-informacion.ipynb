{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de la Información\n",
    "En este notebook nos enfocaremos en extraer la data de los archivos comprimidos y unificar las fuentes de datos. Muchas de los métodos/funciones utilizadas, serán cargadas de un archivo utils.py previamente generado para evitar sobrecarga de código en este notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listar archivos comprimidos y extraer archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=[i for i in os.listdir(\"../\") if i.endswith(\".zip\")] ## ../ hace referencia a un nivel atrás al actual, en donde se encuentran los archivos .zip\n",
    "_=[shutil.unpack_archive(f'../{i}', f'../data/') for i in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##extraer paths de cada archivo csv\n",
    "filepaths=get_csv_filepaths([i.replace(\".zip\",\"\") for i in files])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para leer las fuentes de datos se definirán grupos de archivos denotados por la variable filegroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filegroups=['personajuridica','personanatural','produccion','recaudo','siniestro']     \n",
    "data={}\n",
    "for filegp in filegroups:\n",
    "    data[filegp]=read_by_filegroup(filegp,filepaths,save_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##leer archivos pickle\n",
    "\n",
    "data={}\n",
    "for filegp in filegroups:\n",
    "    data[filegp]=pd.read_pickle(f\"{filegp}.pickle\",compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esquema de generación de la variable objetivo: churn\n",
    "\n",
    "- Se deben explorar los campos que permiten unir las diversas fuentes de información, para ello deberá explorarse el código de asegurado o el número de la póliza\n",
    "- Debido a que solo se tiene un año de historia, debemos tomar un periodo base y observar 12 meses después el comportamiento de los asegurados, para encontrar si renovaron o no (churn) su poliza. A través de este análisis generaremos la variable objetivo. Esto puede observarse en el siguiente gráfico. \n",
    "\n",
    "![img](images/caso_uso_previsora.jpg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total filas antes de remover duplicados:  1054290\n",
      "Total filas después de remover duplicados:  1003437\n"
     ]
    }
   ],
   "source": [
    "##detectar columnas tipo fecha\n",
    "\n",
    "date_cols=[i for i in data['produccion'].columns.values if \"fecha\" in i.lower()]\n",
    "\n",
    "## crear una copia del dataframe para generar reproducibilidad\n",
    "data_prod=data['produccion'].drop_duplicates().copy()\n",
    "\n",
    "def col_to_dateutc(column):\n",
    "    return pd.to_datetime(column,errors=\"coerce\").dt.strftime('%m-%Y')\n",
    "\n",
    "for col in date_cols:\n",
    "    data_prod.loc[:,col]=col_to_dateutc(data_exp['FechaEmision__c'])\n",
    "\n",
    "print(\"Total filas antes de remover duplicados: \",data['produccion'].shape[0])\n",
    "print(\"Total filas después de remover duplicados: \",data_prod.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total emisiones en 02-2021 : 72753 polizas\n",
      "Total emisiones al finalizar el monitoreo en 02-2022 : 52936 polizas\n"
     ]
    }
   ],
   "source": [
    "fecha_inicio=\"02-2021\" ##fecha para iniciar el monitoreo de polizas un año después\n",
    "fecha_fin=\"02-2022\"  ##fecha para finalizar el monitoreo de las pólizas\n",
    "emisiones_inicio=data_prod.query(f'FechaEmision__c==\"{fecha_inicio}\"')\n",
    "emisiones_final=data_prod.query(f'FechaEmision__c==\"{fecha_fin}\"')\n",
    "print(f\"Total emisiones en {fecha_inicio} : {len(set(emisiones_inicio.NumeroPoliza__c.values))} polizas\")\n",
    "print(f\"Total emisiones al finalizar el monitoreo en {fecha_fin} : {len(set(emisiones_final.NumeroPoliza__c.values))} polizas\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7b983b39a226ab5889b4ea3098be3b8cc3b6c7166b049dbd839f1090f7bd1c7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
